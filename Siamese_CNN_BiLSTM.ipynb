{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hgtk\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "def int_sentence(left_texts, right_texts, vocab_index):\n",
    "    left_int = []\n",
    "    right_int = []\n",
    "\n",
    "    for i in range(len(left_texts)):\n",
    "        left_etc = []\n",
    "        right_etc = []\n",
    "        for j in range(len(left_texts[i])):\n",
    "            left_etc.append(vocab_index[left_texts[i][j]])\n",
    "        for j in range(len(right_texts[i])):\n",
    "            right_etc.append(vocab_index[right_texts[i][j]])\n",
    "        left_int.append(left_etc)\n",
    "        right_int.append(right_etc)\n",
    "        \n",
    "    return left_int, right_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = open('file_name_1', 'r', encoding='utf-8-sig')\n",
    "train = open('file_name_2', 'r', encoding='utf-8-sig')\n",
    "cv = open('file_name_3', 'r', encoding='utf-8-sig')\n",
    "test = open('file_name_4', 'r', encoding='utf-8-sig')\n",
    "\n",
    "all_sentence = []\n",
    "\n",
    "for line in All:\n",
    "    line = line.split('\\t')\n",
    "    left = hgtk.text.decompose(line[0])\n",
    "    right = hgtk.text.decompose(line[1])\n",
    "    \n",
    "    etc = []\n",
    "    for i in left:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    all_sentence.append(etc)\n",
    "    \n",
    "    etc = []\n",
    "    for i in right:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    all_sentence.append(etc)\n",
    "    \n",
    "\n",
    "max_len = max([len(i) for i in all_sentence])\n",
    "\n",
    "vocab = set()\n",
    "for line in all_sentence:\n",
    "    for word in line:\n",
    "        vocab.add(word)\n",
    "\n",
    "vocab_size = len(vocab)+1\n",
    "\n",
    "vocab = sorted(list(vocab))\n",
    "\n",
    "vocab_index = {}\n",
    "for i in range(len(vocab)):\n",
    "    vocab_index[vocab[i]] = len(vocab_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_left_sen = []\n",
    "train_right_sen = []\n",
    "train_label = []\n",
    "\n",
    "for line in train:\n",
    "    line = line.split('\\t')\n",
    "    left = hgtk.text.decompose(line[0])\n",
    "    right = hgtk.text.decompose(line[1])\n",
    "    \n",
    "    etc = []\n",
    "    for i in left:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    train_left_sen.append(etc)\n",
    "    \n",
    "    etc = []\n",
    "    for i in right:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    train_right_sen.append(etc)\n",
    "    train_label.append(line[2].strip())\n",
    "\n",
    "cv_left_sen = []\n",
    "cv_right_sen = []\n",
    "cv_label = []\n",
    "\n",
    "for line in cv:\n",
    "    line = line.split('\\t')\n",
    "    left = hgtk.text.decompose(line[0])\n",
    "    right = hgtk.text.decompose(line[1])\n",
    "    \n",
    "    etc = []\n",
    "    for i in left:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    cv_left_sen.append(etc)\n",
    "    \n",
    "    etc = []\n",
    "    for i in right:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    cv_right_sen.append(etc)\n",
    "    cv_label.append(line[2].strip())\n",
    "\n",
    "test_left_sen = []\n",
    "test_right_sen = []\n",
    "test_label = []\n",
    "\n",
    "for line in test:\n",
    "    line = line.split('\\t')\n",
    "    left = hgtk.text.decompose(line[0])\n",
    "    right = hgtk.text.decompose(line[1])\n",
    "    \n",
    "    etc = []\n",
    "    for i in left:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    test_left_sen.append(etc)\n",
    "    \n",
    "    etc = []\n",
    "    for i in right:\n",
    "        if i != 'ᴥ':\n",
    "            etc.append(i + ' ')\n",
    "    test_right_sen.append(etc)\n",
    "    test_label.append(line[2].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_left_int, train_right_int = int_sentence(train_left_sen, train_right_sen, vocab_index)\n",
    "cv_left_int, cv_right_int = int_sentence(cv_left_sen, cv_right_sen, vocab_index)\n",
    "test_left_int, test_right_int = int_sentence(test_left_sen, test_right_sen, vocab_index)\n",
    "\n",
    "train_left = pad_sequences(train_left_int, padding='post', maxlen=max_len)\n",
    "train_right = pad_sequences(train_right_int, padding='post', maxlen=max_len)\n",
    "\n",
    "cv_left = pad_sequences(cv_left_int, padding='post', maxlen=max_len)\n",
    "cv_right = pad_sequences(cv_right_int, padding='post', maxlen=max_len)\n",
    "\n",
    "test_left = pad_sequences(test_left_int, padding='post', maxlen=max_len)\n",
    "test_right = pad_sequences(test_right_int, padding='post', maxlen=max_len)\n",
    "\n",
    "train_label = keras.utils.to_categorical(train_label)\n",
    "cv_label = keras.utils.to_categorical(cv_label)\n",
    "test_label = keras.utils.to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 270)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 270)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 270, 300)     41100       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 270, 256)     230656      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 270, 256)     307456      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 270, 256)     384256      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 270, 100)     122800      conv1d_1[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 270, 100)     122800      conv1d_2[0][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 270, 100)     122800      conv1d_3[0][0]                   \n",
      "                                                                 conv1d_3[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 100)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 100)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 100)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 100)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 100)          0           bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 100)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 100)          0           bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 100)          0           bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 100)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 100)          0           bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1200)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "                                                                 global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2402        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,334,270\n",
      "Trainable params: 1,334,270\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "left_input = layers.Input(shape=(max_len,))\n",
    "right_input = layers.Input(shape=(max_len,))\n",
    "\n",
    "embedded_layer = layers.Embedding(vocab_size, 300)\n",
    "\n",
    "left_emd = embedded_layer(left_input)\n",
    "right_emd = embedded_layer(right_input)\n",
    "\n",
    "cnn3 = layers.Conv1D(filters=256, kernel_size=3, padding='same', activation='relu')\n",
    "cnn4 = layers.Conv1D(filters=256, kernel_size=4, padding='same', activation='relu')\n",
    "cnn5 = layers.Conv1D(filters=256, kernel_size=5, padding='same', activation='relu')\n",
    "\n",
    "left_cnn3 = cnn3(left_emd)\n",
    "right_cnn3 = cnn3(right_emd)\n",
    "\n",
    "left_cnn4 = cnn4(left_emd)\n",
    "right_cnn4 = cnn4(right_emd)\n",
    "\n",
    "left_cnn5 = cnn5(left_emd)\n",
    "right_cnn5 = cnn5(right_emd)\n",
    "\n",
    "lstm3 = layers.Bidirectional(layers.LSTM(50, return_sequences=True))\n",
    "lstm4 = layers.Bidirectional(layers.LSTM(50, return_sequences=True))\n",
    "lstm5 = layers.Bidirectional(layers.LSTM(50, return_sequences=True))\n",
    "\n",
    "left_lstm3 = lstm3(left_cnn3)\n",
    "right_lstm3 = lstm3(right_cnn3)\n",
    "\n",
    "left_lstm4 = lstm4(left_cnn4)\n",
    "right_lstm4 = lstm4(right_cnn4)\n",
    "\n",
    "left_lstm5 = lstm5(left_cnn5)\n",
    "right_lstm5 = lstm5(right_cnn5)\n",
    "\n",
    "left_max3 = layers.GlobalMaxPooling1D()(left_lstm3)\n",
    "left_max4 = layers.GlobalMaxPooling1D()(left_lstm4)\n",
    "left_max5 = layers.GlobalMaxPooling1D()(left_lstm5)\n",
    "\n",
    "right_max3 = layers.GlobalMaxPooling1D()(right_lstm3)\n",
    "right_max4 = layers.GlobalMaxPooling1D()(right_lstm4)\n",
    "right_max5 = layers.GlobalMaxPooling1D()(right_lstm5)\n",
    "\n",
    "left_avg3 = layers.GlobalAveragePooling1D()(left_lstm3)\n",
    "left_avg4 = layers.GlobalAveragePooling1D()(left_lstm4)\n",
    "left_avg5 = layers.GlobalAveragePooling1D()(left_lstm5)\n",
    "\n",
    "right_avg3 = layers.GlobalAveragePooling1D()(right_lstm3)\n",
    "right_avg4 = layers.GlobalAveragePooling1D()(right_lstm4)\n",
    "right_avg5 = layers.GlobalAveragePooling1D()(right_lstm5)\n",
    "\n",
    "concat_layer = layers.Concatenate(axis=1)([left_max3, left_max4, left_max5, left_avg3, left_avg4, left_avg5, right_max3, right_max4, right_max5, right_avg3, right_avg4, right_avg5])\n",
    "\n",
    "outputs = layers.Dense(2, activation='softmax')(concat_layer)\n",
    "\n",
    "model = Model(inputs=[left_input, right_input], outputs=[outputs])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8800 samples, validate on 1100 samples\n",
      "Epoch 1/100\n",
      "8800/8800 [==============================] - 596s 68ms/step - loss: 0.6199 - acc: 0.6355 - val_loss: 0.5702 - val_acc: 0.7064\n",
      "Epoch 2/100\n",
      "8800/8800 [==============================] - 576s 66ms/step - loss: 0.5469 - acc: 0.7139 - val_loss: 0.5332 - val_acc: 0.7455\n",
      "Epoch 3/100\n",
      "8800/8800 [==============================] - 572s 65ms/step - loss: 0.4838 - acc: 0.7724 - val_loss: 0.4698 - val_acc: 0.7809\n",
      "Epoch 4/100\n",
      "8800/8800 [==============================] - 575s 65ms/step - loss: 0.4012 - acc: 0.8257 - val_loss: 0.4480 - val_acc: 0.8045\n",
      "Epoch 5/100\n",
      "8800/8800 [==============================] - 573s 65ms/step - loss: 0.3349 - acc: 0.8636 - val_loss: 0.3983 - val_acc: 0.8273\n",
      "Epoch 6/100\n",
      "8800/8800 [==============================] - 558s 63ms/step - loss: 0.2676 - acc: 0.8999 - val_loss: 0.3732 - val_acc: 0.8355\n",
      "Epoch 7/100\n",
      "8800/8800 [==============================] - 577s 66ms/step - loss: 0.2207 - acc: 0.9207 - val_loss: 0.3802 - val_acc: 0.8373\n",
      "Epoch 8/100\n",
      "8800/8800 [==============================] - 579s 66ms/step - loss: 0.1627 - acc: 0.9499 - val_loss: 0.3610 - val_acc: 0.8455\n",
      "Epoch 9/100\n",
      "8800/8800 [==============================] - 573s 65ms/step - loss: 0.1211 - acc: 0.9673 - val_loss: 0.3514 - val_acc: 0.8509\n",
      "Epoch 10/100\n",
      "8800/8800 [==============================] - 574s 65ms/step - loss: 0.0806 - acc: 0.9819 - val_loss: 0.3509 - val_acc: 0.8482\n",
      "Epoch 11/100\n",
      "8800/8800 [==============================] - 573s 65ms/step - loss: 0.0628 - acc: 0.9887 - val_loss: 0.3807 - val_acc: 0.8427\n",
      "Epoch 12/100\n",
      "8800/8800 [==============================] - 575s 65ms/step - loss: 0.0487 - acc: 0.9900 - val_loss: 0.3910 - val_acc: 0.8609\n",
      "Epoch 13/100\n",
      "8800/8800 [==============================] - 569s 65ms/step - loss: 0.0283 - acc: 0.9974 - val_loss: 0.4053 - val_acc: 0.8709\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51221a4438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.utils.multi_gpu_model(model, gpus=3)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit([train_left, train_right], [train_label], batch_size=64, epochs=100, validation_data=([cv_left, cv_right], [cv_label]), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100/1100 [==============================] - 108s 98ms/step\n",
      "Accuracy: 0.8654545456712897\n",
      "Loss: 0.3541742006215182\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate([test_left, test_right], [test_label])\n",
    "\n",
    "print('Accuracy: '+str(evaluation[1]))\n",
    "print('Loss: '+str(evaluation[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
